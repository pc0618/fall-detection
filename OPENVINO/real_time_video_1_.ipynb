{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e:\\\\JuniorYearSpring\\\\ECE397\\\\openvino test', 'C:\\\\Program Files (x86)\\\\IntelSWTools\\\\openvino\\\\deployment_tools\\\\open_model_zoo\\\\tools\\\\accuracy_checker', 'C:\\\\Program Files (x86)\\\\IntelSWTools\\\\openvino\\\\python\\\\python3.7', 'C:\\\\Program Files (x86)\\\\IntelSWTools\\\\openvino\\\\python\\\\python3', 'C:\\\\Program Files (x86)\\\\IntelSWTools\\\\openvino\\\\deployment_tools\\\\model_optimizer', 'e:\\\\JuniorYearSpring\\\\ECE397\\\\openvino test', 'c:\\\\users\\\\cc\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\python37.zip', 'c:\\\\users\\\\cc\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\DLLs', 'c:\\\\users\\\\cc\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib', 'c:\\\\users\\\\cc\\\\appdata\\\\local\\\\programs\\\\python\\\\python37', '', 'C:\\\\Users\\\\cc\\\\AppData\\\\Roaming\\\\Python\\\\Python37\\\\site-packages', 'c:\\\\users\\\\cc\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages', 'c:\\\\users\\\\cc\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\win32', 'c:\\\\users\\\\cc\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\users\\\\cc\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\Pythonwin', 'c:\\\\users\\\\cc\\\\appdata\\\\local\\\\programs\\\\python\\\\python37\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\cc\\\\.ipython']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.4.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## import packages\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time \n",
    "import cv2\n",
    "# for openvino\n",
    "## before this should run setupvar.bat for openvino\n",
    "from PIL import Image\n",
    "from openvino import inference_engine as ie\n",
    "from openvino.inference_engine import IENetwork, IEPlugin\n",
    "import scipy.io as sio\n",
    "import sys\n",
    "import _thread\n",
    "import threading\n",
    "import time\n",
    "print (sys.path)\n",
    "cv2.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_3': <openvino.inference_engine.ie_api.DataPtr object at 0x000002074B5D39B0>}\n",
      "{'strided_slice/Squeeze_shrink': <openvino.inference_engine.ie_api.DataPtr object at 0x000002074B285050>}\n",
      "{'zero_padding2d_1_input': <openvino.inference_engine.ie_api.DataPtr object at 0x000002074B285050>}\n",
      "{'strided_slice/Squeeze_shrink': <openvino.inference_engine.ie_api.DataPtr object at 0x000002074B285050>}\n"
     ]
    }
   ],
   "source": [
    "# Plugin initialization for specified device and load extensions library if specified.\n",
    "plugin_dir = None\n",
    "model_xml = './ir_model/shirui_saved.xml'\n",
    "model_bin = './ir_model/shirui_saved.bin'\n",
    "# Devices: GPU (intel), CPU, MYRIAD\n",
    "plugin = IEPlugin(\"CPU\", plugin_dirs=plugin_dir)\n",
    "# Read IR\n",
    "net = IENetwork(model=model_xml, weights=model_bin)\n",
    "print(net.inputs)\n",
    "print(net.outputs)\n",
    "input_blob = next(iter(net.inputs))\n",
    "out_blob = next(iter(net.outputs))\n",
    "# Load network to the plugin\n",
    "exec_net = plugin.load(network=net)\n",
    "del net\n",
    "\n",
    "# Plugin initialization for specified device and load extensions library if specified.\n",
    "plugin_dir_f = None\n",
    "model_xml_f = './ir_model/shirui_featrue_extractor_saved.xml'\n",
    "model_bin_f = './ir_model/shirui_featrue_extractor_saved.bin'\n",
    "# Devices: GPU (intel), CPU, MYRIAD\n",
    "plugin_f = IEPlugin(\"CPU\", plugin_dirs=plugin_dir_f)\n",
    "# Read IR\n",
    "net_f = IENetwork(model=model_xml_f, weights=model_bin_f)\n",
    "print(net_f.inputs)\n",
    "print(net_f.outputs)\n",
    "input_blob_f = next(iter(net_f.inputs))\n",
    "out_blob_f = next(iter(net_f.outputs))\n",
    "# Load network to the plugin\n",
    "exec_featrue_extrctor = plugin_f.load(network=net_f)\n",
    "del net_f\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define functions to predict\n",
    "\n",
    "def test_video_realtime(exec_featrue_extrctor,flow, ground_truth,mean_file):\n",
    "    # Load the mean file to subtract to the images\n",
    "    # flow is of shape(224,224,20,n)\n",
    "    num_features = 4096\n",
    "    d = sio.loadmat(mean_file)\n",
    "    flow_mean = d['image_mean']\n",
    "    \n",
    "    flow = flow - np.tile(flow_mean[...,np.newaxis], (1, 1, 1, flow.shape[3]))\n",
    "    flow = np.transpose(flow, (3, 0, 1, 2)) \n",
    "    predictions = np.zeros((flow.shape[0], num_features), dtype=np.float64)\n",
    "    truth = np.zeros((flow.shape[0], 1), dtype=np.float64)\n",
    "      \n",
    "        # Process each stack: do the feed-forward pass\n",
    "    for i in range(flow.shape[0]):\n",
    "        pro_Img = (flow[i]).transpose((2, 0, 1))\n",
    "        prediction = exec_featrue_extrctor.infer(inputs={input_blob_f: np.expand_dims(pro_Img,0)})\n",
    "        # Access the results and get the index of the highest confidence score\n",
    "        output_node_name = list(prediction.keys())[-1]\n",
    "        prediction = prediction[output_node_name]\n",
    "        predictions[i, ...] = prediction\n",
    "        truth[i] = ground_truth\n",
    "        \n",
    "    return predictions, truth\n",
    "\n",
    "\n",
    "def real_time_predict(exec_featrue_extrctor,exec_net,flow_data):\n",
    "    # flow data is of shape (224x,224y,20,n)\n",
    "    num_features = 4096\n",
    "    mean_file = './flow_mean.mat'\n",
    "    save_features = False\n",
    "    save_plots = True\n",
    "\n",
    "    do_training = False\n",
    "    do_testing = True\n",
    "    compute_metrics = True\n",
    "    threshold = 0.5\n",
    "    ground_truth = 0\n",
    "    num_features = 4096\n",
    "\n",
    "    # fold_best_model_path = './urfd_fold_5.h5'\n",
    "    L = 10\n",
    "\n",
    "    X2,truth = test_video_realtime(exec_featrue_extrctor,flow_data, ground_truth,mean_file)\n",
    "\n",
    "    predicted = []\n",
    "    for i in range(len(X2)):\n",
    "        predicted.append(  exec_net.infer(inputs={input_blob:np.asarray(X2[i])}) )\n",
    "    return predicted\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ## set up video stream\n",
    "# capture = cv2.VideoCapture(0)\n",
    "# time.sleep(2.0) # wait for video to start\n",
    "# fps = FPS().start()\n",
    "\n",
    "# cur_images = []\n",
    "# stacked_flow = []\n",
    "# while 1 :\n",
    "#     # capture and show the frame\n",
    "#     ref, frame = capture.read()\n",
    "#     frame = frame[:,::-1,:]\n",
    "#     # print(frame)\n",
    "#     cv2.imshow(\"frame:\",frame)\n",
    "    \n",
    "    \n",
    "#     ###### get the img and the flow ############\n",
    "#     # here name frame needs to contain the current frame in the video\n",
    "    \n",
    "#     # cur_image stores the recent 2 images (in grey reseized format)\n",
    "#     image = cv2.resize(frame, (224, 224), interpolation=cv2.INTER_AREA)  \n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#     if len(cur_images) < 2:\n",
    "#         cur_images.append(image)\n",
    "#     else:\n",
    "#         cur_images.append(image)\n",
    "#         cur_images.pop(0)\n",
    "     \n",
    "#     if len(cur_images) == 2:\n",
    "#         optical_flow = cv2.DualTVL1OpticalFlow_create()\n",
    "#         flow = optical_flow.calc(cur_images[0], cur_images[1], None)\n",
    "\n",
    "#         flow[..., 0] = cv2.normalize(flow[..., 0], None, 0, 255, cv2.NORM_MINMAX)\n",
    "#         flow[..., 1] = cv2.normalize(flow[..., 1], None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "#         # flow contains the current optival flow\n",
    "#         # while stacked flow contains the flow of recent 10 frame\n",
    "#         stacked_flow.append(flow[..., 0])\n",
    "#         stacked_flow.append(flow[..., 1])\n",
    "        \n",
    "# #         if len(stacked_flow) > 20:\n",
    "# #             del stacked_flow[0:2]\n",
    "\n",
    "#     ##### here is the openvino part ###\n",
    "#         if len(stacked_flow) == 24:\n",
    "#             # skip 3 frames\n",
    "#             del stacked_flow[0:4]\n",
    "#             flow_data = np.array(stacked_flow)\n",
    "#             flow_data = flow_data.transpose(1,2,0)\n",
    "#             flow_data = (np.array(stacked_flow)).reshape(224,224,20,1)\n",
    "\n",
    "#             cur_predict = real_time_predict(exec_featrue_extrctor,exec_net,flow_data)\n",
    "\n",
    "#             print(cur_predict)\n",
    "\n",
    "#     #### openvino end\n",
    "    \n",
    "#     key = cv2.waitKey(1) & 0xFF\n",
    "#     if key == ord(\"q\"):\n",
    "#         break\n",
    "#     fps.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_img(cur_images):\n",
    "    while 1 :\n",
    "        # capture and show the frame\n",
    "        ref, frame = capture.read()\n",
    "        frame = frame[:,::-1,:]\n",
    "#         print(frame)\n",
    "\n",
    "\n",
    "        ###### get the img and the flow ############\n",
    "        # here name frame needs to contain the current frame in the video\n",
    "\n",
    "        # cur_image stores the recent 2 images (in grey reseized format)\n",
    "        image = cv2.resize(frame, (224, 224), interpolation=cv2.INTER_AREA)  \n",
    "        cv2.imshow(\"frame:\",image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        cur_images.append(image)\n",
    "        \n",
    "        fps.update()\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "def get_opflow(cur_images,stacked_flow):\n",
    "    while 1:\n",
    "        if len(cur_images) >= 2:\n",
    "            optical_flow = cv2.DualTVL1OpticalFlow_create()\n",
    "            flow = optical_flow.calc(cur_images[0], cur_images[1], None)\n",
    "\n",
    "            flow[..., 0] = cv2.normalize(flow[..., 0], None, 0, 255, cv2.NORM_MINMAX)\n",
    "            flow[..., 1] = cv2.normalize(flow[..., 1], None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "            # flow contains the current optival flow\n",
    "            # while stacked flow contains the flow of recent 10 frame\n",
    "#             lock.acquire()\n",
    "            stacked_flow.append(flow[..., 0])\n",
    "            stacked_flow.append(flow[..., 1])\n",
    "#             lock.release()\n",
    "            cur_images.pop(0)\n",
    "    \n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def detect(stacked_flow):\n",
    "    ##### here is the openvino part ###\n",
    "    while 1:\n",
    "        if len(stacked_flow) >= 20:\n",
    "            # skip 3 frames\n",
    "            \n",
    "            flow_data = np.array(stacked_flow)\n",
    "            flow_data = flow_data.transpose(1,2,0)\n",
    "            flow_data = flow_data.reshape(224,224,20,1)\n",
    "\n",
    "            cur_predict = real_time_predict(exec_featrue_extrctor,exec_net,flow_data)\n",
    "            \n",
    "#             lock.acquire()\n",
    "            del stacked_flow[0:2]\n",
    "#             lock.release()\n",
    "            print(cur_predict)\n",
    "\n",
    "    #### openvino end\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10884"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "time.sleep(2.0) # wait for video to start\n",
    "fps = FPS().start()\n",
    "\n",
    "cur_images = []\n",
    "stacked_flow = []\n",
    "lock = threading.RLock()\n",
    "_thread.start_new_thread( load_img, (cur_images,))\n",
    "_thread.start_new_thread( get_opflow, (cur_images, stacked_flow,) )\n",
    "_thread.start_new_thread( detect, (stacked_flow, ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(222, 224, 20)\n",
      "[{'strided_slice/Squeeze_shrink': array([0.99848807], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.95372635], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.96850014], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.8621522], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.956132], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.51311636], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.41646394], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.92730546], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9997882], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.99844766], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.998156], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9880382], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9576686], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9624133], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9866875], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.8713475], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9222512], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9585054], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9938862], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.95721996], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.99398035], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9804926], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.99868464], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.99986255], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9999823], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.99948066], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.99976295], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.999993], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9999254], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.99995697], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9999391], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9999202], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.98840946], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9929882], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9963027], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.99291337], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.95663196], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9862594], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.96859705], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9940953], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9818533], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.94964826], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.74069154], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.8712901], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.58611965], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.92726344], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.93703634], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.91551733], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9966342], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9998695], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.99828434], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9982], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9996742], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9994233], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9996134], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.994504], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9925754], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.9590006], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.24879353], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.7606536], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.98475695], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.998324], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.98882776], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.8953461], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.8963422], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.97988623], dtype=float32)}]\n",
      "[{'strided_slice/Squeeze_shrink': array([0.8117034], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((20,222,224))\n",
    "a = a.transpose(1,2,0)\n",
    "print(np.shape(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
