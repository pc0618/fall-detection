{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully imported\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import scipy\n",
    "import gc\n",
    "from scipy import misc\n",
    "import glob\n",
    "import cv2\n",
    "# from i3d_inception import Inception_Inflated3d\n",
    "# from i3d_inception import conv3d_bn\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import os\n",
    "import h5py\n",
    "import scipy.io as sio\n",
    "import gc\n",
    "\n",
    "from keras.models import load_model, Model, Sequential\n",
    "from keras.layers import (Input, Conv2D, MaxPooling2D, Flatten,\n",
    "\t\t \t  Activation, Dense, Dropout, ZeroPadding2D)\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold, StratifiedShuffleSplit\n",
    "from keras.layers.advanced_activations import ELU\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Conv3D\n",
    "from keras.layers import MaxPooling3D\n",
    "from keras.layers import AveragePooling3D\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import GlobalAveragePooling3D\n",
    "\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "from keras import optimizers\n",
    "print (\"successfully imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fun\n",
    "def rgb2grey(pic):\n",
    "    size = np.shape(pic)\n",
    "    pic = np.array(pic)\n",
    "    W = size[0]\n",
    "    H = size[1]\n",
    "    rim = pic[:,:,0]\n",
    "    gim = pic[:,:,1]\n",
    "    bim = pic[:,:,2]\n",
    "    return  0.299 * rim + 0.587 * gim + 0.114 * bim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(list1, lits2):\n",
    "    '''\n",
    "    Auxiliar generator: returns the ith element of both given list with each call to next() \n",
    "    '''\n",
    "    for x,y in zip(list1,lits2):\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (224, 224, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test\n",
    "%matplotlib inline \n",
    "image_size=244\n",
    "frame = 10\n",
    "strid = frame//5\n",
    "NUM_RGB_CHANNELS = 3\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "I = tf.read_file(\"URFD_opticalflow/Falls/fall_fall-01/flow_x_00001.jpg\")\n",
    "I = tf.image.decode_jpeg(I, channels=3) \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    I=sess.run((I))\n",
    "#     print (I.shape) \n",
    "#     print (I)\n",
    "    plt.imshow(I) \n",
    "# I.resize((image_size,image_size))\n",
    "print ('Image shape: ',np.shape(I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mean\n",
    "mean_file = 'flow_mean.mat'\n",
    "d = sio.loadmat(mean_file)\n",
    "flow_mean = d['image_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#floders \n",
    "im_folders1 = glob.glob('URFD_opticalflow/Falls//fall*')\n",
    "im_folders2 = glob.glob('URFD_opticalflow/NotFalls//notfall*')\n",
    "im_folders3 = im_folders1+im_folders2\n",
    "np.random.shuffle(im_folders3)\n",
    "\n",
    "#print(im_folders1)\n",
    "#print(im_folders2)\n",
    "# print(im_folders3)\n",
    "final_data = np.empty(shape=(0,224,224,2*frame))\n",
    "final_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 URFD_opticalflow/NotFalls\\notfall_fall-20_post\n",
      "label size: 53\n"
     ]
    }
   ],
   "source": [
    "# loop all the files\n",
    "for i,folder in enumerate(im_folders3[0:1]):\n",
    "    print (i,folder)\n",
    "    flow_x =  glob.glob(folder+'//flow_x*')\n",
    "    flow_x.sort()\n",
    "    flow_y =  glob.glob(folder+'//flow_y*')\n",
    "    flow_y.sort()\n",
    "    nb_stacks = len(flow_x)-frame + 1 # total number of flow groups, one group has frame # images.\n",
    "    flow = np.zeros(shape=(224,224,2*frame,nb_stacks), dtype=np.float64)\n",
    "    gen = generator(flow_x,flow_y)  # yield single x and y image \n",
    "    \n",
    "    for i in range(len(flow_x)):\n",
    "        flow_x_file, flow_y_file = gen.__next__()\n",
    "        img_x = cv2.imread(flow_x_file, cv2.IMREAD_GRAYSCALE)\n",
    "        img_y = cv2.imread(flow_y_file, cv2.IMREAD_GRAYSCALE)\n",
    "        # Assign an image i to the jth stack in the kth position, but also\n",
    "        # in the j+1th stack in the k+1th position and so on\n",
    "        # (for sliding window)\n",
    "        for s in list(reversed(range(min(10,i+1)))):\n",
    "            if i-s < nb_stacks:\n",
    "                flow[:,:,2*s,  i-s] = img_x\n",
    "                flow[:,:,2*s+1,i-s] = img_y\n",
    "        del img_x,img_y\n",
    "#         gc.collect()\n",
    "    del flow_x, flow_y\n",
    "    # Subtract mean\n",
    "    flow = flow - np.tile(flow_mean[...,np.newaxis],(1, 1, 1, flow.shape[3]))\n",
    "    flow = np.transpose(flow, (3, 0, 1, 2)) \n",
    "    final_data=np.concatenate((final_data,flow),axis=0)\n",
    "    #opflow_set = [xyxyxyxyxyxyxyxy]\n",
    "\n",
    "    temp_label =[]\n",
    "    frame_n = len(flow)\n",
    "    del flow\n",
    "    \n",
    "    # detect whether the opflow is in fall folder or notfall folder\n",
    "    if folder in im_folders1:\n",
    "        temp_label+=[1]*frame_n\n",
    "    else:\n",
    "        temp_label+=[0]*frame_n\n",
    "    \n",
    "    final_label.append(temp_label)\n",
    "    print(\"label size:\",np.size(temp_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_lebel (53,)\n",
      "final_data (53, 224, 224, 20)\n"
     ]
    }
   ],
   "source": [
    "# above is label porcess    \n",
    "final_data = np.array(final_data[:])\n",
    "final_label = sum(final_label, []) ## flatten\n",
    "print(\"final_lebel\",np.shape(final_label))\n",
    "print(\"final_data\",np.shape(final_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainx shape: (37, 224, 224, 20)\n",
      "trainy shape: (37,)\n",
      "testx shape: (16, 224, 224, 20)\n",
      "testy shape: (16,)\n"
     ]
    }
   ],
   "source": [
    "final_data_size = np.shape(final_label)\n",
    "final_data_size = final_data_size[0]\n",
    "\n",
    "# here we choose divide data into 7:3, \n",
    "# 7 for training and 3 for test\n",
    "trainx = final_data[:int(final_data_size*0.7)]\n",
    "trainy = final_label[:int(final_data_size*0.7)]\n",
    "\n",
    "testx = final_data[int(final_data_size*0.7):]\n",
    "testy = final_label[int(final_data_size*0.7):]\n",
    "\n",
    "# # transpose the size of opflow data\n",
    "# trainx = trainx.transpose(0,3,2,1)   #\n",
    "# testx = testx.transpose(0,3,2,1)   #\n",
    "\n",
    "print('trainx shape:',np.shape(trainx))\n",
    "print('trainy shape:',np.shape(trainy))\n",
    "\n",
    "print('testx shape:',np.shape(testx))\n",
    "print('testy shape:',np.shape(testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0412 21:16:58.743080  2852 deprecation_wrapper.py:119] From c:\\users\\cc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0412 21:16:58.745075  2852 deprecation_wrapper.py:119] From c:\\users\\cc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0412 21:16:58.765024  2852 deprecation_wrapper.py:119] From c:\\users\\cc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0412 21:16:58.821871  2852 deprecation_wrapper.py:119] From c:\\users\\cc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0412 21:16:59.151988  2852 deprecation_wrapper.py:119] From c:\\users\\cc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0412 21:16:59.179913  2852 deprecation.py:506] From c:\\users\\cc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0412 21:16:59.425287  2852 deprecation_wrapper.py:119] From c:\\users\\cc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0412 21:16:59.431278  2852 deprecation_wrapper.py:119] From c:\\users\\cc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0412 21:16:59.437226  2852 deprecation.py:323] From c:\\users\\cc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "num_features = num_features = 4096\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1), input_shape=(224, 224, 20)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', name='conv1_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', name='conv1_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', name='conv2_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', name='conv2_2'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', name='conv3_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', name='conv4_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_1'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_2'))\n",
    "model.add(ZeroPadding2D((1, 1)))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', name='conv5_3'))\n",
    "model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_features, name='fc6', kernel_initializer='glorot_uniform'))\n",
    "\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(4096, name='fc2', kernel_initializer='glorot_uniform'))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add( Dense(1, name='predictions',kernel_initializer='glorot_uniform'))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "adam = Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999,\n",
    "    epsilon=1e-08)\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy',\n",
    "      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_1 (ZeroPaddin (None, 226, 226, 20)      0         \n",
      "_________________________________________________________________\n",
      "conv1_1 (Conv2D)             (None, 224, 224, 64)      11584     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 226, 226, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2_1 (Conv2D)             (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2_2 (Conv2D)             (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv3_1 (Conv2D)             (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv3_2 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv3_3 (Conv2D)             (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv4_1 (Conv2D)             (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv4_2 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv4_3 (Conv2D)             (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_1 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_2 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv5_3 (Conv2D)             (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1)                 4097      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 134,307,201\n",
      "Trainable params: 134,290,817\n",
      "Non-trainable params: 16,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()   # plot the structure of rgb model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 224, 224, 20)\n",
      "Train on 37 samples, validate on 16 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[25088,4096] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node training/Adam/mul_131}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-bf4b2163e054>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtesty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\cc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\cc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2977\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2979\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2981\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2937\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2938\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\cc\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[25088,4096] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node training/Adam/mul_131}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(trainx))\n",
    "model.fit(trainx,trainy,validation_data=(testx,testy), batch_size=10, shuffle=True,epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
